import { useEffect, useRef, useState, useCallback } from 'react';
import { FaceLandmarker, FilesetResolver } from '@mediapipe/tasks-vision';

export interface FaceLandmark {
  x: number;
  y: number;
  z: number;
}

export interface FaceBlendShapes {
  // ÁõÆ
  eyeBlinkLeft: number;      // Â∑¶ÁõÆ„ÅÆÈñâ„ÅòÂÖ∑Âêà (0-1)
  eyeBlinkRight: number;     // Âè≥ÁõÆ„ÅÆÈñâ„ÅòÂÖ∑Âêà (0-1)
  eyeLookUpLeft: number;     // Â∑¶ÁõÆ„ÅÆ‰∏äÂêë„Åç
  eyeLookUpRight: number;    // Âè≥ÁõÆ„ÅÆ‰∏äÂêë„Åç
  eyeLookDownLeft: number;   // Â∑¶ÁõÆ„ÅÆ‰∏ãÂêë„Åç
  eyeLookDownRight: number;  // Âè≥ÁõÆ„ÅÆ‰∏ãÂêë„Åç
  eyeLookInLeft: number;     // Â∑¶ÁõÆ„ÅÆÂÜÖÂêë„Åç
  eyeLookInRight: number;    // Âè≥ÁõÆ„ÅÆÂÜÖÂêë„Åç
  eyeLookOutLeft: number;    // Â∑¶ÁõÆ„ÅÆÂ§ñÂêë„Åç
  eyeLookOutRight: number;   // Âè≥ÁõÆ„ÅÆÂ§ñÂêë„Åç
  
  // Âè£
  mouthOpen: number;         // Âè£„ÅÆÈñã„ÅçÂÖ∑Âêà (0-1)
  mouthSmile: number;        // Á¨ëÈ°î (0-1)
  mouthPucker: number;       // Âè£„Çí„Åô„Åº„ÇÅ„Çã
  mouthFunnel: number;       // Âè£„Çí‰∏∏„ÇÅ„Çã
  
  // Áúâ
  browInnerUp: number;       // Áúâ„ÅÆ‰∏ä„ÅíÂÖ∑Âêà (0-1)
  browOuterUpLeft: number;   // Â∑¶Áúâ„ÅÆÂ§ñÂÅ¥„ÅÆ‰∏ä„ÅíÂÖ∑Âêà
  browOuterUpRight: number;  // Âè≥Áúâ„ÅÆÂ§ñÂÅ¥„ÅÆ‰∏ä„ÅíÂÖ∑Âêà
  browDownLeft: number;      // Â∑¶Áúâ„Çí‰∏ã„Åí„Çã
  browDownRight: number;     // Âè≥Áúâ„Çí‰∏ã„Åí„Çã
  
  // „Åù„ÅÆ‰ªñ
  jawOpen: number;           // È°é„ÅÆÈñã„Åç
  cheekPuff: number;         // È†¨„ÇíËÜ®„Çâ„Åæ„Åõ„Çã
}

interface UseFaceEstimationReturn {
  faceLandmarks: FaceLandmark[] | null;
  faceBlendShapes: FaceBlendShapes | null;
  isInitialized: boolean;
  isLoading: boolean;
  error: string | null;
  startDetection: () => void;
  stopDetection: () => void;
}

export const useFaceEstimation = (
  videoRef: React.MutableRefObject<HTMLVideoElement | null>
): UseFaceEstimationReturn => {
  const [faceLandmarks, setFaceLandmarks] = useState<FaceLandmark[] | null>(null);
  const [faceBlendShapes, setFaceBlendShapes] = useState<FaceBlendShapes | null>(null);
  const [isInitialized, setIsInitialized] = useState(false);
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [isDetecting, setIsDetecting] = useState(false);

  const faceLandmarkerRef = useRef<FaceLandmarker | null>(null);
  const animationFrameRef = useRef<number | null>(null);
  const lastTimestampRef = useRef<number>(0);
  const lastDetectionTimeRef = useRef<number>(0);
  const DETECTION_INTERVAL = 33; // 30FPSÔºàË°®ÊÉÖ„ÅØÈ´òÈ†ªÂ∫¶„ÅßÊõ¥Êñ∞Ôºâ

  // MediaPipe Face Landmarker„ÅÆÂàùÊúüÂåñ
  useEffect(() => {
    // MediaPipe„ÅÆÊÉÖÂ†±„É≠„Ç∞„ÇíÊäëÂà∂
    const originalConsoleError = console.error;
    console.error = (...args: any[]) => {
      // TensorFlow Lite„ÅÆÊÉÖÂ†±„É°„ÉÉ„Çª„Éº„Ç∏„Çí„Éï„Ç£„É´„Çø„É™„É≥„Ç∞
      const message = args[0]?.toString() || '';
      if (message.includes('Created TensorFlow Lite XNNPACK delegate')) {
        return; // „Åì„ÅÆ„É°„ÉÉ„Çª„Éº„Ç∏„ÅØË°®Á§∫„Åó„Å™„ÅÑ
      }
      originalConsoleError.apply(console, args);
    };

    const initializeFaceLandmarker = async () => {
      try {
        setIsLoading(true);
        setError(null);

        const vision = await FilesetResolver.forVisionTasks(
          'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm'
        );

        faceLandmarkerRef.current = await FaceLandmarker.createFromOptions(vision, {
          baseOptions: {
            modelAssetPath: '/mediapipe/face_landmarker.task',
            delegate: 'GPU'
          },
          runningMode: 'VIDEO',
          numFaces: 1,
          minFaceDetectionConfidence: 0.5,
          minFacePresenceConfidence: 0.5,
          minTrackingConfidence: 0.5,
          outputFaceBlendshapes: true,
          outputFacialTransformationMatrixes: false
        });

        setIsInitialized(true);
      } catch (err) {
        console.error('MediaPipe Face LandmarkerÂàùÊúüÂåñ„Ç®„É©„Éº:', err);
        setError(`Face Landmarker„ÅÆÂàùÊúüÂåñ„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: ${err instanceof Error ? err.message : 'Unknown error'}`);
      } finally {
        setIsLoading(false);
      }
    };

    initializeFaceLandmarker();

    return () => {
      // console.error„ÇíÂÖÉ„Å´Êàª„Åô
      console.error = originalConsoleError;
      
      if (faceLandmarkerRef.current) {
        faceLandmarkerRef.current.close();
      }
    };
  }, []);

  // È°îÊ§úÂá∫„ÅÆ„É´„Éº„Éó
  const detectFace = useCallback(() => {
    if (!faceLandmarkerRef.current || !videoRef.current || !isDetecting) {
      return;
    }

    const video = videoRef.current;
    const currentTime = performance.now();

    // „Éï„É¨„Éº„É†„É¨„Éº„ÉàÂà∂Âæ°
    if (video.readyState >= 2 && (currentTime - lastDetectionTimeRef.current) >= DETECTION_INTERVAL) {
      try {
        const timestamp = Math.max(currentTime, lastTimestampRef.current + 1);
        lastTimestampRef.current = timestamp;
        lastDetectionTimeRef.current = currentTime;

        const result = faceLandmarkerRef.current.detectForVideo(video, timestamp);

        // „É©„É≥„Éâ„Éû„Éº„ÇØ„ÇíÊõ¥Êñ∞
        if (result.faceLandmarks && result.faceLandmarks.length > 0) {
          setFaceLandmarks(result.faceLandmarks[0]);
        } else {
          setFaceLandmarks(null);
        }

        // BlendShape„ÇíÊõ¥Êñ∞
        if (result.faceBlendshapes && result.faceBlendshapes.length > 0) {
          const blendshapes = result.faceBlendshapes[0];
          const categories = blendshapes.categories;

          // „Éá„Éê„ÉÉ„Ç∞: FaceÊ§úÂá∫Áä∂Ê≥Å„Çí„É≠„Ç∞Ôºà10%„ÅÆÁ¢∫ÁéáÔºâ
          if (Math.random() < 0.1) {
            console.log('üé≠ FaceÊ§úÂá∫ÊàêÂäü:', {
              categoriesCount: categories.length,
              firstFewCategories: categories.slice(0, 5).map(c => ({
                name: c.categoryName,
                score: c.score.toFixed(2)
              }))
            });
          }

          // MediaPipe„ÅÆBlendShape„Ç´„ÉÜ„Ç¥„É™„Åã„ÇâÂÄ§„ÇíÊäΩÂá∫
          const getBlendShapeValue = (name: string): number => {
            const category = categories.find(c => c.categoryName === name);
            return category ? category.score : 0;
          };

          setFaceBlendShapes({
            // ÁõÆ
            eyeBlinkLeft: getBlendShapeValue('eyeBlinkLeft'),
            eyeBlinkRight: getBlendShapeValue('eyeBlinkRight'),
            eyeLookUpLeft: getBlendShapeValue('eyeLookUpLeft'),
            eyeLookUpRight: getBlendShapeValue('eyeLookUpRight'),
            eyeLookDownLeft: getBlendShapeValue('eyeLookDownLeft'),
            eyeLookDownRight: getBlendShapeValue('eyeLookDownRight'),
            eyeLookInLeft: getBlendShapeValue('eyeLookInLeft'),
            eyeLookInRight: getBlendShapeValue('eyeLookInRight'),
            eyeLookOutLeft: getBlendShapeValue('eyeLookOutLeft'),
            eyeLookOutRight: getBlendShapeValue('eyeLookOutRight'),
            
            // Âè£
            mouthOpen: getBlendShapeValue('jawOpen'),
            mouthSmile: (getBlendShapeValue('mouthSmileLeft') + getBlendShapeValue('mouthSmileRight')) / 2,
            mouthPucker: getBlendShapeValue('mouthPucker'),
            mouthFunnel: getBlendShapeValue('mouthFunnel'),
            
            // Áúâ
            browInnerUp: getBlendShapeValue('browInnerUp'),
            browOuterUpLeft: getBlendShapeValue('browOuterUpLeft'),
            browOuterUpRight: getBlendShapeValue('browOuterUpRight'),
            browDownLeft: getBlendShapeValue('browDownLeft'),
            browDownRight: getBlendShapeValue('browDownRight'),
            
            // „Åù„ÅÆ‰ªñ
            jawOpen: getBlendShapeValue('jawOpen'),
            cheekPuff: getBlendShapeValue('cheekPuff')
          });
        } else {
          // „Éá„Éê„ÉÉ„Ç∞: FaceÊ§úÂá∫Â§±Êïó„ÅÆ„É≠„Ç∞Ôºà10%„ÅÆÁ¢∫ÁéáÔºâ
          if (Math.random() < 0.1) {
            console.warn('‚ö†Ô∏è FaceÊ§úÂá∫Â§±Êïó:', {
              hasResult: !!result,
              hasFaceBlendshapes: !!result.faceBlendshapes,
              faceBlendshapesLength: result.faceBlendshapes?.length || 0
            });
          }
          setFaceBlendShapes(null);
        }
      } catch (err) {
        console.error('È°îÊ§úÂá∫„Ç®„É©„Éº:', err);
      }
    }

    animationFrameRef.current = requestAnimationFrame(detectFace);
  }, [videoRef, isDetecting]);

  // Ê§úÂá∫„ÅÆÈñãÂßã
  const startDetection = useCallback(() => {
    if (!isInitialized) {
      console.warn('Face Landmarker„ÅåÂàùÊúüÂåñ„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì');
      return;
    }
    setIsDetecting(true);
  }, [isInitialized]);

  // Ê§úÂá∫„ÅÆÂÅúÊ≠¢
  const stopDetection = useCallback(() => {
    setIsDetecting(false);
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }
    setFaceLandmarks(null);
    setFaceBlendShapes(null);
    lastTimestampRef.current = 0;
    lastDetectionTimeRef.current = 0;
  }, []);

  // Ê§úÂá∫„É´„Éº„Éó„ÅÆÈñãÂßã/ÂÅúÊ≠¢
  useEffect(() => {
    if (isDetecting) {
      detectFace();
    }
    return () => {
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
    };
  }, [isDetecting, detectFace]);

  return {
    faceLandmarks,
    faceBlendShapes,
    isInitialized,
    isLoading,
    error,
    startDetection,
    stopDetection
  };
};

